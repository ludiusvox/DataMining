{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 10: SVMs and Hyperparameter Tuning\n",
    "\n",
    "In this lab, you'll be working with Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Loading the Data\n",
    "\n",
    "First, load the data `svm_data_2020.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/svm_data_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Splitting the Data (Group)\n",
    "\n",
    "Now, split the data into a training and test set. 75% of the data should be in the training set, and 25% should be in the testing set.\n",
    "\n",
    "Report the number of positive and negative samples in both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report positive and negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training the Model\n",
    "\n",
    "Now, you will use sklearns [support vector classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) to fit a model to this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fitting the Model and Getting the Support Vectors (Group)\n",
    "\n",
    "Fit the SVC to your split data (using the default hyperparams), and report back the number of support vectors. Use `clf.support_vectors_`, which returns a list of the actual support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create model and get the number of support vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 C hyperparameter vs Support Vector Count (Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C* is the regularization hyperparameter in SVMs, and in this problem you'll be looking at how changing *C* affects the number of support vectors.\n",
    "\n",
    "Implement the function `plot_support_vectors` below, which will plot a line chart of the number of support vectors vs. the value of *C*.\n",
    "\n",
    "**Before implementing the function, predict the answer the following questions**\n",
    "1. As C increases, how will the number of support vectors change?\n",
    "2. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    params: A list of floats, representing the value of C's to try\n",
    "    \n",
    "Output:\n",
    "    None\n",
    "    Print a line chart of the number of support vectors vs. C\n",
    "    \n",
    "Function:\n",
    "    iterate through params\n",
    "        create an SVC classifier for each c\n",
    "        find the length of the support vectors and append to a list\n",
    "    \n",
    "    create a plot with c on the X axis and length of support vectors on Y\n",
    "\"\"\"\n",
    "\n",
    "def plot_support_vectors(params):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1,0.2,0.3,0.5,1,2,3,5,10]\n",
    "plot_support_vectors(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that you have a plot, go back to the questions and explain more using the context of the data. If you were wrong, explain your misconception.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Hyperparam Tuning\n",
    "\n",
    "Compare  the  performance  of  four  different  kernel  functions:  linear (`linear`), polynomial (`poly`),  radial basis function (`rbf`), and `sigmoid`. Not only will you be changing the kernel function, you'll also be optimizing for the different hyperparams.\n",
    "\n",
    "For each type of kernel functions, train your SVM classifiers using the training data and evaluate the resulting SVM classifer using testing data using accuracy, precision, recall and f-measure of the corresponding classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Basic Hyperparameters (Group)\n",
    "\n",
    "Write a function called `best_hyperparams` that when given a dictionary of params, runs a `GridSearchCV` on an SVC model using the training and test data.\n",
    "\n",
    "Use a `cv` of 5.\n",
    "\n",
    "This function will return the optimized classifier `clf`, and the set of best params (using `clf.best_params_`).\n",
    "\n",
    "See the documentation for [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    params_set: A dictionary of params to use for the grid search\n",
    "Output:\n",
    "    The classifier with the best hyperparams\n",
    "    The dict of best params itself\n",
    "    \n",
    "Function:\n",
    "    use gridsearch to find the best SVC classifier\n",
    "    return the best parameters\n",
    "\"\"\"\n",
    "\n",
    "def best_hyperparams(param_set):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the value ranges for each of the params.\n",
    "# We will tell you which of these to tune for which kernel.\n",
    "\n",
    "# C is the regularization paramater we've discussed before\n",
    "C = [0.1,0.2,0.3,0.5,1,2,3,5,10]\n",
    "\n",
    "# degree is the degree of the polynomial used for the polynomial kernel\n",
    "degree = [1,2,3,4,5]\n",
    "\n",
    "# coef is the independent term in the kernel function, and is ony used by poly and sigmoid\n",
    "coef0 = [0.0001,0.001,0.002,0.01,0.02,0.1,0.2,0.3,1,2,5,10]\n",
    "\n",
    "# gamma is the kernel coefficent used for rbf, poly, and sigmoid\n",
    "gamma = [0.0001,0.001,0.002,0.01,0.02,0.1,0.2,0.3,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Kernel (Follow)\n",
    "For the **linear** kernel, tune `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    \"kernel\":[\"linear\"],\n",
    "    \"C\":C\n",
    "}]\n",
    "\n",
    "params, model = best_hyperparams(params)\n",
    "print(params)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly Kernel (Group)\n",
    "For the **polynomial** kernel, tune `C`, `degree` and `coef0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel (Group)\n",
    "For the **rbf** kernel, tune `C` and `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Kernel (Group)\n",
    "\n",
    "For the **sigmoid** kernel, tune `C`, `coef0`, and `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Consider the following visualizaion of how SVM predicts with different kernels on different datasets:\n",
    "\n",
    "![Different Kernels](https://i.imgur.com/HKTLn35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given your results, answer the following questions:\n",
    "\n",
    "1. Which kernel performed best?\n",
    "2. What criteria are you using to define the best model?\n",
    "3. Based on the best-performing model(s), what properties do you think the data have (e.g. is is close to linearly separable)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer here**\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
