{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Template: Phase 2\n",
    "\n",
    "Below are some concrete steps that you can take while doing your analysis for phase3. This guide isn't \"one size fit all\" so you will probably not do everything listed. But it still serves as a good \"pipeline\" for how to do data analysis.\n",
    "\n",
    "If you do engage in a step, you should clearly mention it in the notebook.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Decide on what models you will use and compare\n",
    "\n",
    "Select at least 3 models to compare on your prediction task. At least 2 of your models should be ones we've covered in class. \n",
    "\n",
    "Some resources try to help you select a well-performing model for your data:\n",
    "* [sklearn's Flowchart](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "* [geeks4geeks Flowchart](https://www.geeksforgeeks.org/flowchart-for-basic-machine-learning-models/)\n",
    "* [SAS Cheatsheet](https://blogs.sas.com/content/subconsciousmusings/files/2017/04/machine-learning-cheet-sheet.png)\n",
    "\n",
    "**Note**: These are general guides, and not guarantees of success. Some of the models are also outside of what we have covered, but you can explore them if you want to.\n",
    "\n",
    "In addition to selecting a model you think will perform well, there are other reasons to select a model:\n",
    "* To serve as a baseline (naive) approach you expect to outperform with more complex/appropriate models.\n",
    "* You need a model that is human interpretable (e.g. Decision Tree).\n",
    "* The model has historically performed well on similar tasks.\n",
    "* Some properties of the model are effective for the type of data you have. Remember, at the end of most Seminars, you learned the strengths and weaknesses of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model XXX: I am selecting XXX because...\n",
    "2. Model YYY: I am selecting YYY because...\n",
    "3. Model ZZZ: I am selecting ZZZ because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Split into train and test\n",
    "Make sure to split your data *before* you apply any transformations.\n",
    "\n",
    "**Note**: If you have multiple records from the same object (e.g., multiple attempts from the same student), these should all go in either training or test, but not split between them. See the examples for how to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0      Severity    Start_Time      End_Time     Start_Lat  \\\n",
      "count  1.516064e+06  1.516064e+06  1.516064e+06  1.516064e+06  1.516064e+06   \n",
      "mean   7.580315e+05  2.238630e+00  1.255732e+01  1.265853e+01  3.690056e+01   \n",
      "std    4.376501e+05  6.081481e-01  6.188610e+00  7.072671e+00  5.165653e+00   \n",
      "min    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  2.457022e+01   \n",
      "25%    3.790158e+05  2.000000e+00  8.000000e+00  7.000000e+00  3.385422e+01   \n",
      "50%    7.580315e+05  2.000000e+00  1.400000e+01  1.400000e+01  3.735113e+01   \n",
      "75%    1.137047e+06  2.000000e+00  1.700000e+01  1.800000e+01  4.072593e+01   \n",
      "max    1.516063e+06  4.000000e+00  2.300000e+01  2.300000e+01  4.900058e+01   \n",
      "\n",
      "          Start_Lng       End_Lat       End_Lng  Distance(mi)  Temperature(F)  \\\n",
      "count  1.516064e+06  1.516064e+06  1.516064e+06  1.516064e+06    1.516064e+06   \n",
      "mean  -9.859919e+01  3.690061e+01 -9.859901e+01  5.872617e-01    5.958460e+01   \n",
      "std    1.849602e+01  5.165629e+00  1.849590e+01  1.632659e+00    1.801196e+01   \n",
      "min   -1.244976e+02  2.457011e+01 -1.244978e+02  0.000000e+00   -8.900000e+01   \n",
      "25%   -1.182076e+02  3.385420e+01 -1.182077e+02  0.000000e+00    4.800000e+01   \n",
      "50%   -9.438100e+01  3.735134e+01 -9.437987e+01  1.780000e-01    6.000000e+01   \n",
      "75%   -8.087469e+01  4.072593e+01 -8.087449e+01  5.940000e-01    7.300000e+01   \n",
      "max   -6.711317e+01  4.907500e+01 -6.710924e+01  1.551860e+02    1.706000e+02   \n",
      "\n",
      "       ...    Roundabout       Station          Stop  Traffic_Calming  \\\n",
      "count  ...  1.516064e+06  1.516064e+06  1.516064e+06     1.516064e+06   \n",
      "mean   ...  3.363974e-05  1.856584e-02  1.167233e-02     3.225458e-04   \n",
      "std    ...  5.799882e-03  1.349858e-01  1.074062e-01     1.795667e-02   \n",
      "min    ...  0.000000e+00  0.000000e+00  0.000000e+00     0.000000e+00   \n",
      "25%    ...  0.000000e+00  0.000000e+00  0.000000e+00     0.000000e+00   \n",
      "50%    ...  0.000000e+00  0.000000e+00  0.000000e+00     0.000000e+00   \n",
      "75%    ...  0.000000e+00  0.000000e+00  0.000000e+00     0.000000e+00   \n",
      "max    ...  1.000000e+00  1.000000e+00  1.000000e+00     1.000000e+00   \n",
      "\n",
      "       Traffic_Signal  Turning_Loop  Sunrise_Sunset  Civil_Twilight  \\\n",
      "count    1.516064e+06     1516064.0       1516064.0       1516064.0   \n",
      "mean     1.121120e-01           0.0             0.0             0.0   \n",
      "std      3.155043e-01           0.0             0.0             0.0   \n",
      "min      0.000000e+00           0.0             0.0             0.0   \n",
      "25%      0.000000e+00           0.0             0.0             0.0   \n",
      "50%      0.000000e+00           0.0             0.0             0.0   \n",
      "75%      0.000000e+00           0.0             0.0             0.0   \n",
      "max      1.000000e+00           0.0             0.0             0.0   \n",
      "\n",
      "       Nautical_Twilight  Astronomical_Twilight  \n",
      "count          1516064.0              1516064.0  \n",
      "mean                 0.0                    0.0  \n",
      "std                  0.0                    0.0  \n",
      "min                  0.0                    0.0  \n",
      "25%                  0.0                    0.0  \n",
      "50%                  0.0                    0.0  \n",
      "75%                  0.0                    0.0  \n",
      "max                  0.0                    0.0  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "# set a seed for reproducibility\n",
    "\n",
    "\n",
    "\n",
    "random_seed = 40\n",
    "np.random.seed(random_seed)\n",
    "data = pd.read_csv('/home/aaronlinder/Documents/DataMining/week7/df1.csv')\n",
    "\n",
    "for i in data.columns[data.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "    data[i].fillna(data[i].mean(),inplace=True)\n",
    "print(data.describe())\n",
    "\n",
    "\n",
    "    \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data.to_csv('/home/aaronlinder/Documents/DataMining/week7/df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision Macro: 1.0\n",
      "Recall Macro: 1.0\n",
      "F1 Macro: 1.0\n",
      "Precision Micro: 1.0\n",
      "Recall Micro: 1.0\n",
      "F1 Micro: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     1.0000    1.0000    1.0000      2786\n",
      "           2     1.0000    1.0000    1.0000    121209\n",
      "           3     1.0000    1.0000    1.0000     16042\n",
      "           4     1.0000    1.0000    1.0000     11570\n",
      "\n",
      "    accuracy                         1.0000    151607\n",
      "   macro avg     1.0000    1.0000    1.0000    151607\n",
      "weighted avg     1.0000    1.0000    1.0000    151607\n",
      "\n",
      "X dimensionality (1516064,)\n",
      "y dimensionality (1516064,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The fraction of data that will be test data\n",
    "test_data_fraction = 0.10\n",
    "\n",
    "features = data.iloc[:,0:-1]\n",
    "\"\"\"print(features.head())\n",
    "print(features.describe())\"\"\"\n",
    "labels = data[\"Severity\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=test_data_fraction,  random_state=random_seed)\n",
    "\n",
    "\n",
    "# This is a dummy dataset that contains 500 positive and 500 negative samples\n",
    "\"\"\"X,Y = make_classification(n_features=4, n_redundant=0, n_informative=1, n_clusters_per_class=1)\"\"\"\n",
    "\n",
    "\"\"\"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_data_fraction,  random_state=random_seed)\"\"\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Y_test_predicted = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed).fit(X=X_train, y=Y_train).predict(X_test)\n",
    "print(f'Accuracy: {sklearn.metrics.accuracy_score(Y_test, Y_test_predicted)}')\n",
    "print(f'Precision Macro: {sklearn.metrics.precision_score(Y_test, Y_test_predicted, average=\"macro\")}')\n",
    "print(f'Recall Macro: {sklearn.metrics.recall_score(Y_test, Y_test_predicted, average=\"macro\")}')\n",
    "print(f'F1 Macro: { sklearn.metrics.f1_score(Y_test, Y_test_predicted, average=\"macro\") }')\n",
    "print(f'Precision Micro: {sklearn.metrics.precision_score(Y_test, Y_test_predicted, average=\"micro\")}')\n",
    "print(f'Recall Micro: {sklearn.metrics.recall_score(Y_test, Y_test_predicted, average=\"micro\")}')\n",
    "print(f'F1 Micro: { sklearn.metrics.f1_score(Y_test, Y_test_predicted, average=\"micro\") }')\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test,Y_test_predicted,digits=4))\n",
    "print('X dimensionality', data.Severity.shape)\n",
    "print('y dimensionality', data.Start_Time.shape)\n",
    "# K-Nearest Neighbor Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) Sampling (If needed)\n",
    "\n",
    "\"\"If one of your classes is very underrepresented (e.g. 1000 of Class 0; 200 of Class 1), you might consider oversampling the minority class (e.g. sample 1000 times with replacement from 200 instances), or undersampling the majority class (e.g. sample 200 times from 1000 instances).\n",
    "\n",
    "Check out [np.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) for how to sample a vector.\n",
    "\n",
    "**Note 1**: You should only ever sample the *training dataset*, never the test. After all, you can't chose the class distribution of your test data!\n",
    "\n",
    "**Note 2**: Sampling can help a classifier perform better on the minority class, often at the cost of *overall* performance. But this is no guarantee. If you chose to sample, you should compare your classifiers' performance with and without sampling to see if it actually helped.\n",
    "\n",
    "**Note 3**: Make sure you sample the *same* indices from your training and test data -- otherwise they won't match anymore!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with sampling below (or skip this step if you don't need sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1212382\n",
       "3     161052\n",
       "4     114452\n",
       "1      28178\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Severity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When you're done, write the `sample_data` method to perform sampling on any training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(X_train, Y_train):\n",
    "    subseta = X_train.sample(frac=0.5)\n",
    "    subsetb = Y_train.sample(frac=0.5)\n",
    "   \n",
    "    return subseta, subsetb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your training data to fit any transformers or encoder your need, then apply the fit transformer to your test data. This applies to:\n",
    "* Normalizing/standardizing your features\n",
    "* Using Bag of Words or TF-IDF to encode strings\n",
    "* PCA or dimensionality reduction\n",
    "\n",
    "**Rationale**: In practice, we won't be able to see the test data we'll be making predicting for, so we shouldn't use that data as the basis for any transformation or feature extractio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your feature transformation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When you're done, write the `apply_feature_transformation` method to perform transformation on any training/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_transformation(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Input: The original X_train and X_test feature sets.\n",
    "    Output: The transformed X_train and X_test feature sets.\n",
    "    \"\"\"\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Train and Explore your Models\n",
    "Using the models you decided upon in the beginning, now train these models. Conduct preliminary evaluations to see if using said models are even feasible, before potentially wasting time tuning a model thats no-good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5058    0.5822    0.5413      2786\n",
      "           2     0.8801    0.9357    0.9071    121209\n",
      "           3     0.5302    0.3929    0.4513     16042\n",
      "           4     0.5109    0.3374    0.4064     11570\n",
      "\n",
      "    accuracy                         0.8261    151607\n",
      "   macro avg     0.6067    0.5621    0.5765    151607\n",
      "weighted avg     0.8080    0.8261    0.8139    151607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Y_test_predicted = KNeighborsClassifier(n_neighbors=3).fit(X=X_train, y=Y_train).predict(X_test)\n",
    "print(\"KNN Classifer\")\n",
    "print(classification_report(Y_test,Y_test_predicted,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5) Hyperparameter Tuning\n",
    "For promising models, tune them even further to squeeze out the best possible performance. Some questions to consider.\n",
    "\n",
    "1. What hyperparamaters should I tune? Why?\n",
    "2. What values ranges should I choose for each param? Why?\n",
    "3. Should I use try the values manually, or use the [built-in tuning functions](https://scikit-learn.org/stable/modules/grid_search.html)?\n",
    "\n",
    "**Make sure to only tune on the training dataset!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_best_hyperparameters_m1(X_train, Y_train):\n",
    "    logistic = LogisticRegression()\n",
    "    #penalty = ['l2', 'l2']\n",
    "    C = np.logspace(0,4,10)\n",
    "    hyperparemeters = dict(C=C)\n",
    "    clf =  GridSearchCV(logistic, hyperparemeters, cv=5, verbose=0)\n",
    "   \n",
    "    clfa = clf.fit(X_train,Y_train)\n",
    "    sorted(clfa.cv_results_.keys())\n",
    "    return clfa \n",
    "find_best_hyperparameters_m1(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it All Together\n",
    "\n",
    "Now, combine the \"scratch work\" that you did above into a tidy function that someone could use to replicate your work and process in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate_model1(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    hyperparameters = find_best_hyperparameters_m1(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions\n",
    "    return hyperparameters\n",
    "\n",
    "\n",
    "evaluate_model1(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clfa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9204/780044531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clfa' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
